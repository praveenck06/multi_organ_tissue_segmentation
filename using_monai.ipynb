{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T06:18:52.357161Z",
     "iopub.status.busy": "2022-07-16T06:18:52.355803Z",
     "iopub.status.idle": "2022-07-16T06:19:08.966013Z",
     "shell.execute_reply": "2022-07-16T06:19:08.964361Z",
     "shell.execute_reply.started": "2022-07-16T06:18:52.357115Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install tifffile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tifffile\n",
    "import pathlib\n",
    "import tempfile\n",
    "from glob import glob\n",
    "from prettytable import PrettyTable\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import make_grid, draw_segmentation_masks\n",
    "from torchvision.transforms.functional import convert_image_dtype\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "\n",
    "# from medpy.io import load as mha_load\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import monai\n",
    "from monai.data import create_test_image_2d, list_data_collate, decollate_batch,pad_list_data_collate\n",
    "from monai.inferers import sliding_window_inference, SimpleInferer\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.layers import Norm\n",
    "from monai.utils import ThreadContainer\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "from typing import Union\n",
    "from monai.metrics.utils import do_metric_reduction, ignore_background\n",
    "from monai.utils import MetricReduction\n",
    "\n",
    "from monai.metrics import CumulativeIterationMetric\n",
    "\n",
    "from monai.transforms import *\n",
    "from monai.visualize import plot_2d_or_3d_image\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# print(monai.config.print_config())\n",
    "\n",
    "# log_file_name = f\"experiments/experiment.log\"\n",
    "# logging.basicConfig(\n",
    "#     level= logging.INFO,\n",
    "#     format='%(message)s',\n",
    "#     handlers=[\n",
    "#         logging.FileHandler(log_file_name),\n",
    "#         logging.StreamHandler()]\n",
    "# )\n",
    "# import utils\n",
    "# import importlib as imp\n",
    "\n",
    "# utils = imp.reload(utils)\n",
    "\n",
    "\n",
    "from cmath import nan\n",
    "import monai \n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import tempfile\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "from  tqdm.notebook import tqdm\n",
    "from prettytable import PrettyTable\n",
    "from collections import OrderedDict\n",
    "from skimage.filters import sato, meijering, frangi, hessian\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import make_grid, draw_segmentation_masks\n",
    "from torchvision.transforms.functional import convert_image_dtype\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import cv2\n",
    "import albumentations\n",
    "from PIL import Image\n",
    "# from medpy.io import load as mha_load\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import monai\n",
    "from monai.data import create_test_image_2d, pad_list_data_collate, decollate_batch,pad_list_data_collate\n",
    "from monai.inferers import sliding_window_inference, SimpleInferer\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.optimizers import LearningRateFinder\n",
    "\n",
    "import warnings\n",
    "\n",
    "from typing import Union\n",
    "from monai.metrics.utils import do_metric_reduction, ignore_background\n",
    "from monai.utils import MetricReduction\n",
    "\n",
    "from monai.metrics import CumulativeIterationMetric\n",
    "\n",
    "from monai.transforms import *\n",
    "from monai.visualize import plot_2d_or_3d_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train.csv\n",
      "data/test_images/10078.tiff\n",
      "data/train_annotations/11064.json\n",
      "data/train_images/11448.tiff\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('data/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        break\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def rle_decode(mask_rle, shape, color=1):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.float32)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo : hi] = color\n",
    "    \n",
    "    img = img.reshape(shape).T\n",
    "#     print(img.shape)\n",
    "    print(\"before\", np.unique(img))\n",
    "    img[img>0] =1 \n",
    "    print(\"after\", np.unique(img))\n",
    "    return img\n",
    "\n",
    "def read_image(image_path):\n",
    "    return  tifffile.imread(image_path)\n",
    "def load_segmentation_mask(mask_rle):\n",
    "    return rle_decode(mask_rle, (3000,3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images =glob(\"data/train_images/*.tiff\")\n",
    "annotations = glob(\"data/train_annotations/*.json\")\n",
    "len(images)\n",
    "len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>organ</th>\n",
       "      <th>data_source</th>\n",
       "      <th>img_height</th>\n",
       "      <th>img_width</th>\n",
       "      <th>pixel_size</th>\n",
       "      <th>tissue_thickness</th>\n",
       "      <th>rle</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10044</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1459676 77 1462675 82 1465674 87 1468673 92 14...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10274</td>\n",
       "      <td>prostate</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>715707 2 718705 8 721703 11 724701 18 727692 3...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10392</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1228631 20 1231629 24 1234624 40 1237623 47 12...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10488</td>\n",
       "      <td>lung</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>3446519 15 3449517 17 3452514 20 3455510 24 34...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10610</td>\n",
       "      <td>spleen</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>478925 68 481909 87 484893 105 487863 154 4908...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>9517</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1611763 11 1614753 29 1617750 35 1620746 43 16...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>9769</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3070</td>\n",
       "      <td>3070</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4030400 28 4033466 34 4036526 48 4039594 54 40...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>9777</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>538473 13 541468 22 544463 30 547461 35 550459...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>9791</td>\n",
       "      <td>kidney</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>334733 33 337729 43 340729 43 343725 51 346723...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>9904</td>\n",
       "      <td>largeintestine</td>\n",
       "      <td>HPA</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1009165 7 1012149 28 1015140 38 1018127 51 102...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id           organ data_source  img_height  img_width  pixel_size  \\\n",
       "0    10044        prostate         HPA        3000       3000         0.4   \n",
       "1    10274        prostate         HPA        3000       3000         0.4   \n",
       "2    10392          spleen         HPA        3000       3000         0.4   \n",
       "3    10488            lung         HPA        3000       3000         0.4   \n",
       "4    10610          spleen         HPA        3000       3000         0.4   \n",
       "..     ...             ...         ...         ...        ...         ...   \n",
       "346   9517          kidney         HPA        3000       3000         0.4   \n",
       "347   9769          kidney         HPA        3070       3070         0.4   \n",
       "348   9777  largeintestine         HPA        3000       3000         0.4   \n",
       "349   9791          kidney         HPA        3000       3000         0.4   \n",
       "350   9904  largeintestine         HPA        3000       3000         0.4   \n",
       "\n",
       "     tissue_thickness                                                rle  \\\n",
       "0                   4  1459676 77 1462675 82 1465674 87 1468673 92 14...   \n",
       "1                   4  715707 2 718705 8 721703 11 724701 18 727692 3...   \n",
       "2                   4  1228631 20 1231629 24 1234624 40 1237623 47 12...   \n",
       "3                   4  3446519 15 3449517 17 3452514 20 3455510 24 34...   \n",
       "4                   4  478925 68 481909 87 484893 105 487863 154 4908...   \n",
       "..                ...                                                ...   \n",
       "346                 4  1611763 11 1614753 29 1617750 35 1620746 43 16...   \n",
       "347                 4  4030400 28 4033466 34 4036526 48 4039594 54 40...   \n",
       "348                 4  538473 13 541468 22 544463 30 547461 35 550459...   \n",
       "349                 4  334733 33 337729 43 340729 43 343725 51 346723...   \n",
       "350                 4  1009165 7 1012149 28 1015140 38 1018127 51 102...   \n",
       "\n",
       "      age     sex  \n",
       "0    37.0    Male  \n",
       "1    76.0    Male  \n",
       "2    82.0    Male  \n",
       "3    78.0    Male  \n",
       "4    21.0  Female  \n",
       "..    ...     ...  \n",
       "346  61.0    Male  \n",
       "347  28.0    Male  \n",
       "348  84.0    Male  \n",
       "349  28.0    Male  \n",
       "350  84.0    Male  \n",
       "\n",
       "[351 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train.csv\", dtype={\"id\":str})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data source, Age and Gender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-07-16T06:12:35.178160Z",
     "iopub.status.busy": "2022-07-16T06:12:35.177786Z",
     "iopub.status.idle": "2022-07-16T06:12:35.631257Z",
     "shell.execute_reply": "2022-07-16T06:12:35.630277Z",
     "shell.execute_reply.started": "2022-07-16T06:12:35.178123Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,6))\n",
    "plt.subplot(1,4,1)\n",
    "plt.pie(df.groupby(\"data_source\")[\"id\"].count(), labels=df[\"data_source\"].unique())\n",
    "plt.title(\"Data source\")\n",
    "plt.subplot(1,4,2)\n",
    "plt.pie(df[\"sex\"].value_counts(), labels= df[\"sex\"].unique())\n",
    "plt.title(\"Gender\")\n",
    "plt.subplot(1,4,3)\n",
    "plt.hist(x=df[\"age\"],label=\"age\")\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Age\")\n",
    "plt.subplot(1,4,4)\n",
    "sns.countplot(x=\"organ\", order=df[\"organ\"].value_counts(ascending=True).index ,data=df)\n",
    "plt.title(\"Organ\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image height width and pixel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-07-16T06:12:35.633229Z",
     "iopub.status.busy": "2022-07-16T06:12:35.632609Z",
     "iopub.status.idle": "2022-07-16T06:12:36.055543Z",
     "shell.execute_reply": "2022-07-16T06:12:36.054577Z",
     "shell.execute_reply.started": "2022-07-16T06:12:35.633191Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(x=df[\"img_height\"])\n",
    "plt.xlabel(\"img_height\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"img_height\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(x=df[\"img_width\"])\n",
    "plt.title(\"img_width\")\n",
    "plt.xlabel(\"img_width\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(x=df[\"pixel_size\"])\n",
    "plt.title(\"pixel_size\")\n",
    "plt.xlabel(\"pixel_size\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-07-16T06:12:36.056930Z",
     "iopub.status.busy": "2022-07-16T06:12:36.056663Z",
     "iopub.status.idle": "2022-07-16T06:12:38.164892Z",
     "shell.execute_reply": "2022-07-16T06:12:38.162987Z",
     "shell.execute_reply.started": "2022-07-16T06:12:36.056905Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,14))\n",
    "\n",
    "sample_image = tifffile.imread(images[0])\n",
    "plt.imshow(sample_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T08:45:53.692204Z",
     "iopub.status.busy": "2022-07-16T08:45:53.691265Z",
     "iopub.status.idle": "2022-07-16T08:45:53.701432Z",
     "shell.execute_reply": "2022-07-16T08:45:53.700428Z",
     "shell.execute_reply.started": "2022-07-16T08:45:53.692164Z"
    }
   },
   "outputs": [],
   "source": [
    "image_path_prefix = \"/kaggle/input/hubmap-organ-segmentation/train_images/\"\n",
    "image_path_sufix = \".tiff\"\n",
    "df[\"image_path\"] = image_path_prefix+ df[\"id\"] + image_path_sufix\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T08:45:54.517102Z",
     "iopub.status.busy": "2022-07-16T08:45:54.516486Z",
     "iopub.status.idle": "2022-07-16T08:45:54.554152Z",
     "shell.execute_reply": "2022-07-16T08:45:54.553142Z",
     "shell.execute_reply.started": "2022-07-16T08:45:54.517064Z"
    }
   },
   "outputs": [],
   "source": [
    "train_files = [{\"image\": train_df.iloc[i,-1], \"label\":train_df.iloc[i,-4]} for i in range(len(train_df))]\n",
    "val_files = [{\"image\": val_df.iloc[i,-1], \"label\":val_df.iloc[i,-4]} for i in range(len(val_df))]\n",
    "\n",
    "print(len(train_files), len(val_files))\n",
    "\n",
    "threshold =0\n",
    "IMAGE_SIZE_1 = 512\n",
    "IMAGE_SIZE_2 = 512   # 3072 = 1024 * 3\n",
    "CLIP_LIMIT =(1,2)\n",
    "TRAIN_BATCH_SIZE = 2\n",
    "VAL_BATCH_SIZE = 1 # 16\n",
    "TEST_BATCH_SIZE = 1\n",
    "\n",
    "LEARNING_RATE = 1e-2\n",
    "\n",
    "both_keys = [\"image\", \"label\"]\n",
    "\n",
    "\n",
    "train_transforms = Compose([\n",
    "    Lambdad(keys=\"image\", func=read_image),\n",
    "    Lambdad(keys=\"label\", func=load_segmentation_mask),\n",
    "    AddChanneld(keys=\"label\"),\n",
    "    AsChannelFirstd(keys=\"image\"),\n",
    "    EnsureTyped(keys=both_keys),\n",
    "    Resized(both_keys, spatial_size=(IMAGE_SIZE_1, IMAGE_SIZE_2)),\n",
    "    NormalizeIntensityd(keys=[\"image\"], channel_wise=True), ## normalizing images only , subtrahend=mean, divisor=std \n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    Lambdad(keys=\"image\", func=read_image),\n",
    "    Lambdad(keys=\"label\", func=load_segmentation_mask),\n",
    "    AddChanneld(keys=\"label\"),\n",
    "    AsChannelFirstd(keys=\"image\"),\n",
    "    EnsureTyped(keys=both_keys),\n",
    "    Resized(both_keys, spatial_size=(IMAGE_SIZE_1, IMAGE_SIZE_2)),\n",
    "    NormalizeIntensityd(keys=[\"image\"], channel_wise=True), ## normalizing images only , subtrahend=mean, divisor=std \n",
    "\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T08:45:55.431360Z",
     "iopub.status.busy": "2022-07-16T08:45:55.430733Z",
     "iopub.status.idle": "2022-07-16T08:45:55.438570Z",
     "shell.execute_reply": "2022-07-16T08:45:55.437295Z",
     "shell.execute_reply.started": "2022-07-16T08:45:55.431324Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = monai.data.Dataset(data=train_files, transform=train_transforms) #, num_workers=8\n",
    "train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=8,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        collate_fn=pad_list_data_collate,\n",
    "#         pin_memory=torch.cuda.is_available(),\n",
    "    )\n",
    "\n",
    "val_ds = monai.data.Dataset(data=val_files, transform=val_transforms) #, num_workers=8\n",
    "val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        num_workers=1,\n",
    "        collate_fn=pad_list_data_collate,\n",
    "#         pin_memory=torch.cuda.is_available(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T08:45:57.282100Z",
     "iopub.status.busy": "2022-07-16T08:45:57.281303Z",
     "iopub.status.idle": "2022-07-16T08:46:15.775937Z",
     "shell.execute_reply": "2022-07-16T08:46:15.774417Z",
     "shell.execute_reply.started": "2022-07-16T08:45:57.282056Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "for batch in train_loader:\n",
    "    plt.figure(figsize=(16,16))\n",
    "    image, label = batch[\"image\"], batch[\"label\"]\n",
    "    image = image.permute(0,2,3,1)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image[0])\n",
    "    plt.title(image.shape)\n",
    "    plt.subplot(1,2,2)\n",
    "    label = label.permute(0,2,3,1)\n",
    "#     label[label>threshold] =1  \n",
    "\n",
    "    plt.imshow(label[0])\n",
    "    plt.title(label.shape)\n",
    "    plt.show()\n",
    "    break\n",
    "    \n",
    "for batch in val_loader:\n",
    "    plt.figure(figsize=(16,16))\n",
    "    image, label = batch[\"image\"], batch[\"label\"]\n",
    "    image = image.permute(0,2,3,1)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image[0])\n",
    "    plt.title(image.shape)\n",
    "    plt.subplot(1,2,2)\n",
    "    label = label.permute(0,2,3,1)\n",
    "#     label[label>threshold] =1  \n",
    "    plt.imshow(label[0])\n",
    "    plt.title(str(label.shape) + str(np.unique(label)))\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T08:22:21.528228Z",
     "iopub.status.busy": "2022-07-16T08:22:21.527858Z",
     "iopub.status.idle": "2022-07-16T08:22:21.571108Z",
     "shell.execute_reply": "2022-07-16T08:22:21.570216Z",
     "shell.execute_reply.started": "2022-07-16T08:22:21.528200Z"
    }
   },
   "outputs": [],
   "source": [
    "dice_and_iou_metrics = []\n",
    "thresholds = np.arange(start=0.5, stop=1, step=0.05)\n",
    "\n",
    "## instantiating metric, \n",
    "dice_metric_fn = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "### UNET dont have activations in last layer, so using post transforms we pass model output and get sigmoid output\n",
    "post_trans_fn = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5), KeepLargestConnectedComponent(applied_labels=[1], connectivity=1) ]) # \n",
    "\n",
    "def get_metrics_object_at_different_thresholds():\n",
    "    ## instantiating metrics for all the thresholds\n",
    "    for index , threshold in  enumerate(thresholds):\n",
    "        threshold = round(threshold, ndigits=2)\n",
    "        dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "        post_trans = Compose([EnsureType(), Activations(sigmoid=True),AsDiscrete(threshold=threshold), KeepLargestConnectedComponent(applied_labels=[1], connectivity=1)]) #\n",
    "        metric_transforms_dict = {\"dice_metric\":dice_metric, \"post_trans\":post_trans}\n",
    "        dice_and_iou_metrics.append(metric_transforms_dict)\n",
    "    return dice_and_iou_metrics\n",
    "        \n",
    "dice_and_iou_metrics = get_metrics_object_at_different_thresholds()\n",
    "## method to calculate IoU and Dice metric for each thresholds\n",
    "def calculate_mean_dice_and_iou_metric(y_pred, y):\n",
    "    \n",
    "    for index , threshold in  enumerate(thresholds):\n",
    "        threshold = round(threshold, ndigits=2)\n",
    "        post_trans = dice_and_iou_metrics[index][\"post_trans\"]\n",
    "        val_outputs = [post_trans(i) for i in decollate_batch(y_pred)]\n",
    "        dice_and_iou_metrics[index][\"dice_metric\"](y_pred=val_outputs, y=y)\n",
    "\n",
    "## method to aggreate batch results and average them acorss all threshold   \n",
    "def aggregate_dice_and_iou_metric():\n",
    "    average_dice_metrics = torch.randn((len(thresholds)))\n",
    "    t = PrettyTable(['treshold', 'dice metric'])\n",
    "\n",
    "    for index , threshold in  enumerate(thresholds):\n",
    "        threshold = round(threshold, ndigits=2)\n",
    "        dice_metric = dice_and_iou_metrics[index][\"dice_metric\"].aggregate()\n",
    "        average_dice_metrics[index] = dice_metric\n",
    "        dice_and_iou_metrics[index][\"dice_metric\"].reset()\n",
    "        \n",
    "        t.add_row([threshold, round(dice_metric.item(), ndigits=4)])\n",
    "    mean_average_dice_metric =  torch.mean(average_dice_metrics).item(),\n",
    "    t.add_row([\"Mean@0.5:0.95\", round(mean_average_dice_metric[0], ndigits=4)])\n",
    "    logging.info(t)\n",
    "    return  mean_average_dice_metric[0]\n",
    "\n",
    "    \n",
    "def train_model(model, train_loader,val_loader, tensorboard_writer_path,device,learning_rate, epochs =1000):    \n",
    "    loss_function = monai.losses.DiceCELoss(sigmoid=True, to_onehot_y=False,squared_pred=True, include_background=True)   \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='max', factor=0.56 , patience=4, verbose=True)\n",
    "    # scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=6.6e-6, max_lr=6.6e-3, mode=\"triangular2\",step_size_up=6*len(train_loader), cycle_momentum=False)#\n",
    "    scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=266, eta_min=0, last_epoch=-1)\n",
    "    val_interval = 2\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    epoch_loss_values = list()\n",
    "    metric_values = list()\n",
    "    writer = SummaryWriter(f\"runs/{tensorboard_writer_path}\")\n",
    "    epochs = epochs\n",
    "    pathlib.Path('experiments').mkdir(parents=True, exist_ok=True) \n",
    "    log_file_name = f\"experiments/{tensorboard_writer_path}.log\"\n",
    "    logging.basicConfig(level= logging.INFO,format='%(message)s',handlers=[logging.FileHandler(log_file_name),logging.StreamHandler()])\n",
    "    \n",
    "  \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        logging.info(\"-\" * 10)\n",
    "        logging.info(f\"epoch {epoch + 1}/{epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{epochs}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        writer.add_scalar(\"learning_rate\", optimizer.param_groups[0]['lr'], epoch + 1)\n",
    "        # scheduler.step(best_metric)\n",
    "\n",
    "        logging.info(f\"learning_rate: { optimizer.param_groups[0]['lr']}\")\n",
    "        print(f\"learning_rate: { optimizer.param_groups[0]['lr']}\")\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            inputs, labels = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # outputs = sliding_window_inference(inputs, (1024, 1024), 3, model)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            if loss.item() == np.nan:\n",
    "                print(outputs)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_len = (len(train_loader)*train_loader.batch_size )// train_loader.batch_size\n",
    "            \n",
    "            scheduler.step()  # for cyclic learning rate\n",
    "            \n",
    "            if step % 2== 0:\n",
    "                logging.info(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "                print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "            \n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        logging.info(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "        \n",
    "        if  (epoch + 1) % val_interval == 0:\n",
    "            print(\"validation\")\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_images = None\n",
    "                val_labels = None\n",
    "                val_outputs = None\n",
    "                val_epoch_loss = 0\n",
    "                val_steps = 0\n",
    "                for val_data in val_loader:\n",
    "                    \n",
    "                    val_steps +=1\n",
    "                    val_images, val_labels = val_data[\"image\"].to(device), val_data[\"label\"].to(device)\n",
    "                    # with torch.cuda.amp.autocast(enabled=False):\n",
    "                    # val_outputs = sliding_window_inference(val_images, (1024, 1024), 3, model)\n",
    "                    val_outputs =  model(val_images)\n",
    "                    val_loss = loss_function(val_outputs, val_labels)\n",
    "                    val_epoch_loss+=val_loss\n",
    "                    raw_val_outputs = val_outputs.detach()\n",
    "                    val_outputs = [post_trans_fn(i) for i in decollate_batch(val_outputs)]\n",
    "                    \n",
    "                    calculate_mean_dice_and_iou_metric(y_pred=raw_val_outputs, y=val_labels )\n",
    "                    \n",
    "                # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "                    if val_steps == 1:\n",
    "                        for i in range(VAL_BATCH_SIZE):\n",
    "                            if epoch ==1:\n",
    "                                plot_2d_or_3d_image(val_images, epoch + 1, writer, index=i, tag=\"val\"+str(i)+\"/image\")\n",
    "                                plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=i, tag=\"val\"+str(i)+\"/label\")\n",
    "                            plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=i, tag=\"val\"+str(i)+\"/output\")\n",
    "                # aggregate the final mean dice result\n",
    "                \n",
    "                metric = aggregate_dice_and_iou_metric()\n",
    "                val_epoch_loss /= val_steps\n",
    "                metric_values.append(metric)\n",
    "                if metric > best_metric:\n",
    "                    best_metric = metric\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    pathlib.Path('models').mkdir(parents=True, exist_ok=True) \n",
    "                    torch.save(model, f\"models/{tensorboard_writer_path}.pth\")\n",
    "                    logging.info(\"saved new best metric model\")\n",
    "                    print(\"saved new best metric model\")\n",
    "                logging.info(\n",
    "                    \"current epoch: {} current mean DICE @ 0.95: {:.4f} best mean DICE @ 0.95: {:.4f} at epoch {}\".format(\n",
    "                        epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                print(\n",
    "                    \"current epoch: {} current mean DICE @ 0.95: {:.4f} best mean DICE @ 0.95: {:.4f} at epoch {}\".format(\n",
    "                        epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                    )\n",
    "                )\n",
    "                writer.add_scalar(\"val_mean_DICE@0.5:0.95\", metric, epoch + 1)\n",
    "                writer.add_scalars(\"loss\", {\"train\":epoch_loss, \"validation\": val_epoch_loss}, epoch + 1)\n",
    "                \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    logging.info(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "    writer.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T08:22:24.068532Z",
     "iopub.status.busy": "2022-07-16T08:22:24.068127Z",
     "iopub.status.idle": "2022-07-16T08:22:24.097563Z",
     "shell.execute_reply": "2022-07-16T08:22:24.096605Z",
     "shell.execute_reply.started": "2022-07-16T08:22:24.068492Z"
    }
   },
   "outputs": [],
   "source": [
    "largest_connector_model  = monai.networks.nets.UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=3,\n",
    "    out_channels=1,\n",
    "    channels=(8, 16, 32, 64, 128),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    dropout=0.36,\n",
    "    num_res_units=1,\n",
    "    norm=\"batch\",\n",
    ").to(device)\n",
    "experiment_name = \"testing\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T08:22:43.250821Z",
     "iopub.status.busy": "2022-07-16T08:22:43.250186Z",
     "iopub.status.idle": "2022-07-16T08:39:27.437976Z",
     "shell.execute_reply": "2022-07-16T08:39:27.435494Z",
     "shell.execute_reply.started": "2022-07-16T08:22:43.250772Z"
    }
   },
   "outputs": [],
   "source": [
    "train_model(\n",
    "    model=largest_connector_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    tensorboard_writer_path=experiment_name,\n",
    "    device=device,\n",
    "    learning_rate=2.6e-2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T08:20:55.714139Z",
     "iopub.status.busy": "2022-07-16T08:20:55.713771Z",
     "iopub.status.idle": "2022-07-16T08:20:55.719577Z",
     "shell.execute_reply": "2022-07-16T08:20:55.718632Z",
     "shell.execute_reply.started": "2022-07-16T08:20:55.714098Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.info(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T08:16:55.136720Z",
     "iopub.status.busy": "2022-07-16T08:16:55.136252Z",
     "iopub.status.idle": "2022-07-16T08:17:02.982183Z",
     "shell.execute_reply": "2022-07-16T08:17:02.980896Z",
     "shell.execute_reply.started": "2022-07-16T08:16:55.136678Z"
    }
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi_organ_tissue_segmentation",
   "language": "python",
   "name": "multi_organ_tissue_segmentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
